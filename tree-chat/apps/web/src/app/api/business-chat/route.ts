import { NextRequest, NextResponse } from 'next/server';

// Get LangGraph API URL from environment variable
const LANGGRAPH_API_URL = process.env.LANGGRAPH_API_URL || (
  process.env.NODE_ENV === 'production' ? 'http://127.0.0.1:2025' : 'http://localhost:2025'
);

interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
}

interface BusinessChatRequest {
  businessName: string;
  canvasData: Record<string, string>;
  message: string;
  chatHistory: ChatMessage[];
}

interface CanvasSuggestion {
  sectionId: string;
  currentValue: string;
  suggestedValue: string;
  reasoning: string;
}

interface BusinessChatResponse {
  success: boolean;
  response: string;
  canvasSuggestions?: CanvasSuggestion[];
  metadata?: {
    reasoning?: string;
    searchQueries?: string[];
    model?: string;
  };
  errors?: string[];
}

export async function POST(request: NextRequest) {
  try {
    const body: BusinessChatRequest = await request.json();
    
    console.log('API: Received business chat request:', JSON.stringify(body, null, 2));

    // Call the LangGraph business chat agent
    console.log('LLM: Calling business chat agent for:', body.businessName);
    
    const langGraphResponse = await fetch(`${LANGGRAPH_API_URL}/threads`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        assistant_id: 'd2549018-4a23-4d33-aa0c-d7f5dc905ab6', // business_chat_agent ID with Tavily
        input: {
          businessName: body.businessName,
          canvasData: body.canvasData,
          message: body.message,
          chatHistory: body.chatHistory
        }
      })
    });

    if (!langGraphResponse.ok) {
      throw new Error(`LangGraph API call failed: ${langGraphResponse.status} ${langGraphResponse.statusText}`);
    }

    const threadResult = await langGraphResponse.json();
    console.log('LangGraph thread created:', threadResult.thread_id);

    // Now invoke the thread to get the response
    const invokeResponse = await fetch(`${LANGGRAPH_API_URL}/threads/${threadResult.thread_id}/runs`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        assistant_id: 'd2549018-4a23-4d33-aa0c-d7f5dc905ab6', // business_chat_agent ID with Tavily
        input: {
          businessName: body.businessName,
          canvasData: body.canvasData,
          message: body.message,
          chatHistory: body.chatHistory
        }
      })
    });

    if (!invokeResponse.ok) {
      throw new Error(`LangGraph invoke failed: ${invokeResponse.status} ${invokeResponse.statusText}`);
    }

    const runResult = await invokeResponse.json();
    console.log('LangGraph run result:', JSON.stringify(runResult, null, 2));

    // Wait for the run to complete and get the final result
    const runId = runResult.run_id;
    let finalResult = runResult;
    
    // Poll for completion (max 30 seconds)
    const maxAttempts = 60;
    let attempts = 0;
    
    while (finalResult.status === 'pending' && attempts < maxAttempts) {
      await new Promise(resolve => setTimeout(resolve, 500));
      
      const statusResponse = await fetch(`${LANGGRAPH_API_URL}/threads/${threadResult.thread_id}/runs/${runId}`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        }
      });
      
      if (statusResponse.ok) {
        finalResult = await statusResponse.json();
        console.log(`Run status attempt ${attempts + 1}:`, finalResult.status);
      }
      
      attempts++;
    }
    
    console.log('Final LangGraph result:', JSON.stringify(finalResult, null, 2));

    // Get the final state values from the completed run
    const valuesResponse = await fetch(`${LANGGRAPH_API_URL}/threads/${threadResult.thread_id}/state`, {
      method: 'GET',
      headers: {
        'Content-Type': 'application/json',
      }
    });
    
    let graphOutput = {};
    
    if (valuesResponse.ok) {
      const stateData = await valuesResponse.json();
      console.log('Thread state data:', JSON.stringify(stateData, null, 2));
      
      // Extract the output from the state
      if (stateData.values && stateData.values.output) {
        graphOutput = stateData.values.output;
        console.log('Found output from thread state:', graphOutput);
      } else if (stateData.values && stateData.values.response) {
        // Fallback: use response directly
        graphOutput = {
          response: stateData.values.response,
          success: true,
          metadata: {
            reasoning: stateData.values.reasoning || 'Generated by LangGraph business chat agent',
            searchQueries: stateData.values.searchQueries || [],
            model: 'gpt-4o'
          }
        };
        console.log('Using response fallback from thread state:', graphOutput);
      } else {
        console.log('No output or response found in thread state. Available keys:', Object.keys(stateData.values || {}));
        graphOutput = {
          response: "申し訳ございませんが、回答を生成できませんでした。もう一度お試しください。",
          success: false,
          metadata: {
            reasoning: 'No response generated - possibly incomplete agent execution',
            model: 'gpt-4o'
          }
        };
      }
    } else {
      console.error('Failed to get thread state:', valuesResponse.status, valuesResponse.statusText);
      graphOutput = {
        response: "申し訳ございませんが、システムエラーが発生しました。もう一度お試しください。",
        success: false,
        metadata: {
          reasoning: 'Thread state retrieval failed',
          model: 'gpt-4o',
          error: `State retrieval failed: ${valuesResponse.status} ${valuesResponse.statusText}`
        }
      };
    }

    // Extract the response from the LangGraph response
    const output = graphOutput as any;
    
    const response: BusinessChatResponse = {
      success: true,
      response: output?.response || "申し訳ございませんが、回答を生成できませんでした。",
      canvasSuggestions: output?.canvasSuggestions,
      metadata: output?.metadata || {
        reasoning: 'Generated by LangGraph business chat agent',
        model: 'gpt-4o'
      }
    };

    console.log('API: Sending response:', JSON.stringify(response, null, 2));
    
    return NextResponse.json(response);

  } catch (error) {
    console.error('Business chat API route error:', error);
    
    return NextResponse.json({
      success: false,
      response: "申し訳ございませんが、エラーが発生しました。もう一度お試しください。",
      metadata: {
        reasoning: 'Error occurred during processing',
        model: 'gpt-4o',
        error: error instanceof Error ? error.message : 'Unknown error'
      }
    }, { status: 500 });
  }
}